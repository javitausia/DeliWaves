{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction of the coastal wave climate with RBF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cases are already propagated and we now have a lot of different waves with\n",
    "different characteristics propagated all along the coast so the reconstruction of the wave climate must be done.\n",
    "\n",
    "The reconstruction of the wave climate in shallow waters is carried out by\n",
    "an interpolation from the selected case series that have been propagated from\n",
    "undefined depths. The interpolation technique used is based on radial basis\n",
    "functions (RBF), very suitable for data with high dimensionality and not evenly\n",
    "distributed. There is a series of values of the real function\n",
    "$f(x_i) \\:\\:\\: i = 1, ..., N$ in the points $x_1 , ..., x_N$. The RBF\n",
    "interpolation technique considers that the RBF function approximation consists of a linear combination of symmetrical radial functions centered on the given points. The objective function has the following expression:\n",
    "\n",
    "\\begin{equation*}\n",
    "RBF(x) = p(x) + \\sum_{i=1}^{N}a_i\\Phi\\left ( \\left \\| x-x_i \\right \\| \\right )\n",
    "\\end{equation*}\n",
    "\n",
    "interpolating the given values as follows:\n",
    "\n",
    "\\begin{equation*}\n",
    "RBF(x_i) = f_i \\:\\:\\: i = 1 ,..., N\n",
    "\\end{equation*}\n",
    "\n",
    "where $RBF$ is the interpolation function, $p(x)$ is the linear polynomial in all the\n",
    "variables involved in the problem, $a_i$ are the RBF adjustment coefficients, $\\Phi$ is the\n",
    "basic radial function, $||\\cdot||$ is the Euclidean norm and $x_i$ are the centres of\n",
    "the RBF interpolation.\n",
    "\n",
    "![RBF](../images/rbf/rbf.png)\n",
    "\n",
    "The polynomial $p(x)$ in the expression of the RBF interpolation function is defined as a\n",
    "monomial base ${p_0, p_1 ,..., p_d}$. The first is a monomial, consisting of a number of grade one monomials equal to the dimensionality of the data, where $b = {b_0 , b_1 ,..., b_d}$ are the coefficients of these monomials.\n",
    "\n",
    "The radially based functions can have different expressions. Some of these\n",
    "radial functions contain a shape parameter that plays a very important role\n",
    "in the precision of the technique. In the methodology of propagation of the maritime climate, it has been considered the Gaussian radial function that depend on a shape parameter.\n",
    "\n",
    "Notice that the RBF reconstruction is done for each CSIRO reanalysis partition, but all these partitions must be grouped together for the buoy validation and the final estimations of both the profile of the beach and the surfing regional index, this is explained below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common \n",
    "import sys\n",
    "import os\n",
    "import os.path as op\n",
    "\n",
    "# basic \n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta as td\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# dev library \n",
    "sys.path.insert(0, os.getcwd())\n",
    "\n",
    "# RBF module \n",
    "from rbf_main import RBF_Reconstruction\n",
    "import rbf_functions as rbff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_data = op.join(os.getcwd(), '..', 'data', 'projects-swan')\n",
    "\n",
    "# -------------- EDIT THIS PART --------------------------------------------- #\n",
    "name = 'SAF'               # used name in the SWAN section\n",
    "resolution = str(0.0042)   # used resolution in the SWAN section (see the folder name)\n",
    "num_cases = str(20)        # num cases in the SWAN section\n",
    "# --------------------------------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUBSETS\n",
    "subsetsea    = pd.read_pickle(op.join(p_data, name+'-SEA-'+resolution,\n",
    "                                      'sea_cases_'+num_cases+'.pkl'))\n",
    "subsetsea    = subsetsea[['hs', 'per', 'dir', 'spr']]\n",
    "\n",
    "subsetswell  = pd.read_pickle(op.join(p_data, name+'-SWELL-'+resolution,\n",
    "                                      'swell_cases_'+num_cases+'.pkl'))\n",
    "subsetswell  = subsetswell[['hs', 'per', 'dir', 'spr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TARGETS\n",
    "targetsea    = xr.open_dataset(op.join(p_data, name+'-SEA-'+resolution,\n",
    "                                       'sea_propagated_'+num_cases+'.nc'))\n",
    "targetswell  = xr.open_dataset(op.join(p_data, name+'-SWELL-'+resolution,\n",
    "                                       'swell_propagated_'+num_cases+'.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction desired point\n",
    "\n",
    "# ------- EDIT THE DESIRED POINT ------- #\n",
    "lat = -34.0\n",
    "lon = 24.96\n",
    "# -------------------------------------- #\n",
    "\n",
    "lat = np.where((targetsea.Y.values<lat+0.005) & \n",
    "               (targetsea.Y.values>lat-0.005))[0][0]\n",
    "lon = np.where((targetswell.X.values<lon+0.005) &\n",
    "               (targetswell.X.values>lon-0.005))[0][0]\n",
    "targetsea   = targetsea.isel(X=lon).isel(Y=lat)\n",
    "targetswell = targetswell.isel(X=lon).isel(Y=lat)\n",
    "targetsea   = pd.DataFrame({'hs': targetsea.Hsig.values,\n",
    "                            'per': targetsea.TPsmoo.values,\n",
    "                            'perM': targetsea.Tm02.values,\n",
    "                            'dir': targetsea.Dir.values,\n",
    "                            'spr': targetsea.Dspr.values})\n",
    "seaedit         = subsetsea.mean()\n",
    "seaedit['perM'] = 7.0\n",
    "targetsea       = targetsea.fillna(seaedit)\n",
    "targetswell = pd.DataFrame({'hs': targetswell.Hsig.values,\n",
    "                            'per': targetswell.TPsmoo.values,\n",
    "                            'perM': targetswell.Tm02.values,\n",
    "                            'dir': targetswell.Dir.values,\n",
    "                            'spr': targetswell.Dspr.values})\n",
    "swelledit         = subsetswell.mean()\n",
    "swelledit['perM'] = 12.0\n",
    "targetswell       = targetswell.fillna(swelledit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 360840 entries, 1979-01-01 00:00:00 to 2020-02-29 23:00:00\n",
      "Data columns (total 29 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   Hs         360840 non-null  float32\n",
      " 1   Tm_01      360839 non-null  float32\n",
      " 2   Tm_02      360840 non-null  float32\n",
      " 3   Tp         360839 non-null  float32\n",
      " 4   DirM       360839 non-null  float32\n",
      " 5   DirP       360839 non-null  float32\n",
      " 6   Spr        360839 non-null  float32\n",
      " 7   Nwp        360840 non-null  float32\n",
      " 8   U10        360840 non-null  float32\n",
      " 9   V10        360840 non-null  float32\n",
      " 10  W          360840 non-null  float64\n",
      " 11  DirW       360832 non-null  float64\n",
      " 12  Hsea       360840 non-null  float32\n",
      " 13  Hswell1    360840 non-null  float32\n",
      " 14  Hswell2    360840 non-null  float32\n",
      " 15  Hswell3    360840 non-null  float32\n",
      " 16  Tpsea      172510 non-null  float32\n",
      " 17  Tpswell1   321377 non-null  float32\n",
      " 18  Tpswell2   138960 non-null  float32\n",
      " 19  Tpswell3   46833 non-null   float32\n",
      " 20  Dirsea     172510 non-null  float32\n",
      " 21  Dirswell1  321377 non-null  float32\n",
      " 22  Dirswell2  138960 non-null  float32\n",
      " 23  Dirswell3  46833 non-null   float32\n",
      " 24  Sprsea     172510 non-null  float32\n",
      " 25  Sprswell1  321377 non-null  float32\n",
      " 26  Sprswell2  138960 non-null  float32\n",
      " 27  Sprswell3  46833 non-null   float32\n",
      " 28  Hs_cal     360840 non-null  float32\n",
      "dtypes: float32(27), float64(2)\n",
      "memory usage: 45.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# DATASETS\n",
    "dataset_tot = pd.read_pickle(op.join(p_data, '..', 'hindcast',\n",
    "                                     'csiro_dataframe_sat_corr.pkl'))\n",
    "print(dataset_tot.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the seas and swells to perform the reconstruction as shown:\n",
    "\n",
    "labels_input   = [['Hsea', 'Tpsea', 'Dirsea', 'Sprsea'],\n",
    "                  ['Hswell1', 'Tpswell1','Dirswell1', 'Sprswell1'],\n",
    "                  ['Hswell2', 'Tpswell2','Dirswell2', 'Sprswell2'],\n",
    "                  ['Hswell3', 'Tpswell3','Dirswell3', 'Sprswell3']]\n",
    "labels_output  = [['Hsea', 'Tpsea', 'Tm_02', 'Dirsea', 'Sprsea'],\n",
    "                  ['Hswell1', 'Tpswell1', 'Tm_02','Dirswell1', 'Sprswell1'],\n",
    "                  ['Hswell2', 'Tpswell2', 'Tm_02','Dirswell2', 'Sprswell2'],\n",
    "                  ['Hswell3', 'Tpswell3', 'Tm_02','Dirswell3', 'Sprswell3']]\n",
    "datasets = []\n",
    "\n",
    "for ss in labels_input:\n",
    "    dataset_ss = dataset_tot[ss]\n",
    "    dataset_ss = dataset_ss.dropna(axis=0, how='any')\n",
    "    datasets.append(dataset_ss)\n",
    "    \n",
    "dataframes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing RFB reconstruction... \n",
      "\n",
      "ix_scalar: 0,  optimization: 0.11 | interpolation: 8.87\n",
      "ix_scalar: 1,  optimization: 0.02 | interpolation: 8.91\n",
      "ix_scalar: 2,  optimization: 0.03 | interpolation: 7.65\n",
      "ix_scalar: 4,  optimization: 0.02 | interpolation: 8.36\n",
      "ix_directional: 3,  optimization: 0.12 | interpolation: 16.18\n",
      "ix_scalar: 0,  optimization: 0.03 | interpolation: 14.21\n",
      "ix_scalar: 1,  optimization: 0.03 | interpolation: 14.09\n",
      "ix_scalar: 2,  optimization: 0.03 | interpolation: 13.62\n",
      "ix_scalar: 4,  optimization: 0.03 | interpolation: 13.54\n",
      "ix_directional: 3,  optimization: 0.12 | interpolation: 28.56\n",
      "ix_scalar: 0,  optimization: 0.03 | interpolation: 6.79\n",
      "ix_scalar: 1,  optimization: 0.04 | interpolation: 8.03\n",
      "ix_scalar: 2,  optimization: 0.04 | interpolation: 6.60\n",
      "ix_scalar: 4,  optimization: 0.03 | interpolation: 6.16\n",
      "ix_directional: 3,  optimization: 0.12 | interpolation: 12.65\n",
      "ix_scalar: 0,  optimization: 0.03 | interpolation: 2.42\n",
      "ix_scalar: 1,  optimization: 0.02 | interpolation: 2.15\n",
      "ix_scalar: 2,  optimization: 0.03 | interpolation: 2.16\n",
      "ix_scalar: 4,  optimization: 0.03 | interpolation: 2.07\n",
      "ix_directional: 3,  optimization: 0.13 | interpolation: 4.24\n",
      "                         Hsea      Tpsea      Dirsea     Sprsea  Hswell1  \\\n",
      "1979-01-01 01:00:00  0.099482   2.953173  204.343449   4.095659      NaN   \n",
      "1979-01-01 02:00:00  0.210036   4.061287  198.065639   7.033435      NaN   \n",
      "1979-01-01 03:00:00  0.268401   4.550586  188.764957  10.957688      NaN   \n",
      "1979-01-01 04:00:00  0.286856   4.682704  176.532204  15.296342      NaN   \n",
      "1979-01-01 05:00:00  0.282762   4.806092  151.637187  20.805933  0.14121   \n",
      "...                       ...        ...         ...        ...      ...   \n",
      "2020-02-29 19:00:00  0.609084  11.705774  180.597470   6.868525      NaN   \n",
      "2020-02-29 20:00:00  0.598838  11.644345  180.814582   6.825435      NaN   \n",
      "2020-02-29 21:00:00  0.599884  11.543654  180.710670   6.955936      NaN   \n",
      "2020-02-29 22:00:00  0.596462  11.595804  180.124029   7.167384      NaN   \n",
      "2020-02-29 23:00:00  0.589174  11.738964  178.604256   7.671786      NaN   \n",
      "\n",
      "                     Tpswell1   Dirswell1  Sprswell1  Hswell2  Tpswell2  \\\n",
      "1979-01-01 01:00:00       NaN         NaN        NaN      NaN       NaN   \n",
      "1979-01-01 02:00:00       NaN         NaN        NaN      NaN       NaN   \n",
      "1979-01-01 03:00:00       NaN         NaN        NaN      NaN       NaN   \n",
      "1979-01-01 04:00:00       NaN         NaN        NaN      NaN       NaN   \n",
      "1979-01-01 05:00:00  5.252029  173.514005    5.21554      NaN       NaN   \n",
      "...                       ...         ...        ...      ...       ...   \n",
      "2020-02-29 19:00:00       NaN         NaN        NaN      NaN       NaN   \n",
      "2020-02-29 20:00:00       NaN         NaN        NaN      NaN       NaN   \n",
      "2020-02-29 21:00:00       NaN         NaN        NaN      NaN       NaN   \n",
      "2020-02-29 22:00:00       NaN         NaN        NaN      NaN       NaN   \n",
      "2020-02-29 23:00:00       NaN         NaN        NaN      NaN       NaN   \n",
      "\n",
      "                     Dirswell2  Sprswell2  Hswell3  Tpswell3  Dirswell3  \\\n",
      "1979-01-01 01:00:00        NaN        NaN      NaN       NaN        NaN   \n",
      "1979-01-01 02:00:00        NaN        NaN      NaN       NaN        NaN   \n",
      "1979-01-01 03:00:00        NaN        NaN      NaN       NaN        NaN   \n",
      "1979-01-01 04:00:00        NaN        NaN      NaN       NaN        NaN   \n",
      "1979-01-01 05:00:00        NaN        NaN      NaN       NaN        NaN   \n",
      "...                        ...        ...      ...       ...        ...   \n",
      "2020-02-29 19:00:00        NaN        NaN      NaN       NaN        NaN   \n",
      "2020-02-29 20:00:00        NaN        NaN      NaN       NaN        NaN   \n",
      "2020-02-29 21:00:00        NaN        NaN      NaN       NaN        NaN   \n",
      "2020-02-29 22:00:00        NaN        NaN      NaN       NaN        NaN   \n",
      "2020-02-29 23:00:00        NaN        NaN      NaN       NaN        NaN   \n",
      "\n",
      "                     Sprswell3      Tm_02  \n",
      "1979-01-01 01:00:00        NaN   2.289763  \n",
      "1979-01-01 02:00:00        NaN   3.268202  \n",
      "1979-01-01 03:00:00        NaN   3.708912  \n",
      "1979-01-01 04:00:00        NaN   3.834873  \n",
      "1979-01-01 05:00:00        NaN   4.360869  \n",
      "...                        ...        ...  \n",
      "2020-02-29 19:00:00        NaN  10.342103  \n",
      "2020-02-29 20:00:00        NaN  10.276397  \n",
      "2020-02-29 21:00:00        NaN  10.173505  \n",
      "2020-02-29 22:00:00        NaN  10.210385  \n",
      "2020-02-29 23:00:00        NaN  10.319220  \n",
      "\n",
      "[360839 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "print('Performing RFB reconstruction... \\n')\n",
    "\n",
    "# RBF \n",
    "for count, dat in enumerate(datasets):\n",
    "    # Scalar and directional columns\n",
    "    ix_scalar_subset = [0,1,3]\n",
    "    ix_directional_subset = [2]\n",
    "    ix_scalar_target = [0,1,2,4]\n",
    "    ix_directional_target = [3] \n",
    "    # RBF for the seas\n",
    "    if count==0:\n",
    "        # Calculating subset, target and dataset\n",
    "        subset  = subsetsea.to_numpy()\n",
    "        target  = targetsea.to_numpy()\n",
    "        dat_index = dat.index\n",
    "        dataset = dat.to_numpy()\n",
    "        # Performing RBF\n",
    "        output = RBF_Reconstruction(\n",
    "                    subset, ix_scalar_subset, ix_directional_subset,\n",
    "                    target, ix_scalar_target, ix_directional_target,\n",
    "                    dataset\n",
    "                    )\n",
    "        # Reconstrucing the new dataframe\n",
    "        for l, lab in enumerate(labels_output[count]):\n",
    "            if l==0:\n",
    "                output_dataframe = pd.DataFrame({lab: output[:,l]}, \n",
    "                                                 index=dat_index)\n",
    "            else:\n",
    "                output_dataframe[lab] = output[:,l]\n",
    "        # Appending all new dataframes    \n",
    "        dataframes.append(output_dataframe)\n",
    "    # RBF for the swellls    \n",
    "    else:\n",
    "        # Calculating subset, target and dataset\n",
    "        subset  = subsetswell.to_numpy()\n",
    "        target  = targetswell.to_numpy()\n",
    "        dat_index = dat.index\n",
    "        dataset = dat.to_numpy()\n",
    "        # Performing RBF\n",
    "        output = RBF_Reconstruction(\n",
    "                    subset, ix_scalar_subset, ix_directional_subset,\n",
    "                    target, ix_scalar_target, ix_directional_target,\n",
    "                    dataset\n",
    "                    )\n",
    "        # Reconstrucing the new dataframe\n",
    "        for l, lab in enumerate(labels_output[count]):\n",
    "            if l==0:\n",
    "                output_dataframe = pd.DataFrame({lab: output[:,l]}, \n",
    "                                                 index=dat_index)\n",
    "            else:\n",
    "                output_dataframe[lab] = output[:,l]\n",
    "        # Appending all new dataframes        \n",
    "        dataframes.append(output_dataframe)\n",
    "\n",
    "# SAVE final file\n",
    "reconstructed_dataframe = pd.concat(dataframes, axis=1)\n",
    "\n",
    "# But we first maintain just one Tm, as they are all the same\n",
    "Tm_02 = reconstructed_dataframe['Tm_02'].mean(axis=1)\n",
    "reconstructed_dataframe = reconstructed_dataframe.drop(columns=['Tm_02'])\n",
    "reconstructed_dataframe['Tm_02'] = Tm_02\n",
    "\n",
    "# Saving\n",
    "reconstructed_dataframe.to_pickle(op.join(p_data, '..', 'reconstructed',\n",
    "                                  'reconstructed_partitioned_'+name+'.pkl'))\n",
    "\n",
    "print(reconstructed_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the reconstruction has been performed, we now have different partitions propagated in the selected point. These propagations can be added to obtain the requested bulk variables for both the validation with coastal buoys and the creation of the surfing index if wanted. This can be done using two different methods:\n",
    "\n",
    "- Bulk parameters\n",
    "- Spectral parameters\n",
    "\n",
    "In this case, we will use the bulk reconstruction, as it is easier and much more important, faster, but a notebook is also added that uses the spectral reconstruction, explained in detail there.\n",
    "\n",
    "For the bulk or aggregated conditions, the following formulas are used to calculate the significant wave height, the wave peak period and the wave mean direction:\n",
    "\n",
    "\\begin{equation*}\n",
    "H_S=\\sqrt{\\sum_{i=1}^{N}H_{Si}^{2}}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "T_P=\\sqrt{\\frac{\\sum_{i=1}^{N}H_{Si}}{\\sum_{i=1}^{N}\\frac{H_{Si}}{T_{Pi}^{2}}}}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\theta_m=\\arctan{\\frac{\\sum_{i=1}^{N}H_{Si}^{2} \\: T_{Pi} \\: \\sin{\\theta_i}}{\\sum_{i=1}^{N}H_{Si}^{2} \\: T_{Pi} \\: \\cos{\\theta_i}}}\n",
    "\\end{equation*}\n",
    "\n",
    "where using them, these aggregated parameters can be obtained, leading to a complete reconstructed dataframe in the desired point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First copy to play with NaNs\n",
    "agg = reconstructed_dataframe.copy()\n",
    "agg[['Tpsea', 'Tpswell1', 'Tpswell2', 'Tpswell3']] = \\\n",
    "    agg[['Tpsea', 'Tpswell1', 'Tpswell2', 'Tpswell3']].fillna(np.inf)\n",
    "agg = agg.fillna(0.0)\n",
    "\n",
    "# Bulk Hs\n",
    "reconstructed_dataframe['Hs_Agg'] = np.sqrt(\n",
    "        agg['Hsea']**2 +\n",
    "        agg['Hswell1']**2 +\n",
    "        agg['Hswell2']**2 +\n",
    "        agg['Hswell3']**2\n",
    "        )\n",
    "\n",
    "# Bulk Tp\n",
    "reconstructed_dataframe['Tp_Agg'] = np.sqrt(\n",
    "        reconstructed_dataframe['Hs_Agg']**2 / (agg['Hsea']**2/agg['Tpsea']**2 + \n",
    "                          agg['Hswell1']**2/agg['Tpswell1']**2 +\n",
    "                          agg['Hswell2']**2/agg['Tpswell2']**2 +\n",
    "                          agg['Hswell3']**2/agg['Tpswell3']**2)\n",
    "        )\n",
    "        \n",
    "# Second copy to play with NaNs\n",
    "agg = reconstructed_dataframe.copy().fillna(0.0)\n",
    "\n",
    "# Bulk Dir\n",
    "reconstructed_dataframe['Dir_Agg'] = np.arctan(\n",
    "        (agg['Hsea']*agg['Tpsea']*np.sin(agg['Dirsea']*np.pi/180) +\n",
    "         agg['Hswell1']*agg['Tpswell1']*np.sin(agg['Dirswell1']*np.pi/180) +\n",
    "         agg['Hswell2']*agg['Tpswell2']*np.sin(agg['Dirswell2']*np.pi/180) +\n",
    "         agg['Hswell3']*agg['Tpswell3']*np.sin(agg['Dirswell3']*np.pi/180)) /\n",
    "        (agg['Hsea']*agg['Tpsea']*np.cos(agg['Dirsea']*np.pi/180) +\n",
    "         agg['Hswell1']*agg['Tpswell1']*np.cos(agg['Dirswell1']*np.pi/180) +\n",
    "         agg['Hswell2']*agg['Tpswell2']*np.cos(agg['Dirswell2']*np.pi/180) +\n",
    "         agg['Hswell3']*agg['Tpswell3']*np.cos(agg['Dirswell3']*np.pi/180))\n",
    "        )\n",
    "reconstructed_dataframe['Dir_Agg'] = reconstructed_dataframe['Dir_Agg']*180/np.pi\n",
    "reconstructed_dataframe['Dir_Agg'] = reconstructed_dataframe['Dir_Agg'].where(reconstructed_dataframe['Dir_Agg']>0, \n",
    "                                          reconstructed_dataframe['Dir_Agg']+360)\n",
    "\n",
    "# Wind features\n",
    "reconstructed_dataframe = reconstructed_dataframe.join(dataset_tot[['W', 'DirW']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## In case coastal buoy exists\n",
    "#print('Extracting Buoy information...')\n",
    "#\n",
    "#buoy = pd.read_pickle(op.join(p_data, 'buoy', 'COAST-BUOY FILE NAME'))\n",
    "#buoy.index = buoy.index.round('H')\n",
    "#buoy = buoy.drop_duplicates()\n",
    "#buoy_index = sorted(buoy.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## In case spectral reconstruction has been performed\n",
    "#print('Concatinating and plotting data...')\n",
    "#\n",
    "#csiro_spec = pd.read_csv(op.join(p_data, 'spectra',\n",
    "#                                 'NAME_specsrecon.csv'))\n",
    "#csiro_spec.index = csiro_spec[csiro_spec.columns.values[0]].values\n",
    "#csiro_spec = csiro_spec.drop(columns=csiro_spec.columns.values[0]) \n",
    "#csiro = csiro.join(csiro_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 360839 entries, 1979-01-01 01:00:00 to 2020-02-29 23:00:00\n",
      "Freq: H\n",
      "Data columns (total 22 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   Hsea       172510 non-null  float64\n",
      " 1   Tpsea      172510 non-null  float64\n",
      " 2   Dirsea     172510 non-null  float64\n",
      " 3   Sprsea     172510 non-null  float64\n",
      " 4   Hswell1    321377 non-null  float64\n",
      " 5   Tpswell1   321377 non-null  float64\n",
      " 6   Dirswell1  321377 non-null  float64\n",
      " 7   Sprswell1  321377 non-null  float64\n",
      " 8   Hswell2    138960 non-null  float64\n",
      " 9   Tpswell2   138960 non-null  float64\n",
      " 10  Dirswell2  138960 non-null  float64\n",
      " 11  Sprswell2  138960 non-null  float64\n",
      " 12  Hswell3    46833 non-null   float64\n",
      " 13  Tpswell3   46833 non-null   float64\n",
      " 14  Dirswell3  46833 non-null   float64\n",
      " 15  Sprswell3  46833 non-null   float64\n",
      " 16  Tm_02      360839 non-null  float64\n",
      " 17  Hs_Agg     360839 non-null  float64\n",
      " 18  Tp_Agg     360839 non-null  float64\n",
      " 19  Dir_Agg    360839 non-null  float64\n",
      " 20  W          360839 non-null  float64\n",
      " 21  DirW       360831 non-null  float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 73.3 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(reconstructed_dataframe.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_dataframe.to_pickle(op.join(p_data, '..', 'reconstructed',\n",
    "                                  'reconstructed_'+name+'.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN THIS CELL BELOW TO COMPARE THE OBTAINED RESULTS\n",
    "\n",
    "### (Hindcast | Buoy)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "total = reconstructed_dataframe.join(buoy, how='inner')\n",
    "\n",
    "total_plot = total[['Hs_Buoy', 'Tp_Buoy', 'Dir_Buoy',\n",
    "                    'Hs_Agg', 'Tp_Agg', 'Dir_Agg',\n",
    "                    'Hs_Spec', 'Tp_Spec', 'Dir_Spec',\n",
    "                    'Hsea', 'Tpsea', 'Dirsea',\n",
    "                    'Hswell1', 'Tpswell1', 'Dirswell1']]\n",
    "        \n",
    "labels = ['$H_S$ [m]', '$T_P$ [s]', '$\\u03B8$ [$\\degree$]']\n",
    "\n",
    "validation_data = total_plot.copy()\n",
    "\n",
    "register_matplotlib_converters()\n",
    "year = 2005\n",
    "ini = str(year)+'-01-01 00:00:00'\n",
    "end = str(year)+'-12-31 23:00:00'\n",
    "total_plot = total_plot.loc[ini:end]\n",
    "fig, axs = plt.subplots(3, 1, figsize=(20,15), sharex=True)\n",
    "fig.subplots_adjust(hspace=0.05, wspace=0.1)\n",
    "fig.suptitle('Year: ' +str(year)+ ', ' +name+ ' buoy compared with propagated CSIRO',\n",
    "             fontsize=22, y=0.94, fontweight='bold')\n",
    "months = ['                        Jan', '                        Feb', '                        Mar', \n",
    "          '                        Apr', '                        May', '                        Jun', \n",
    "          '                        Jul', '                        Aug', '                        Sep', \n",
    "          '                        Oct', '                        Nov', '                        Dec']\n",
    "i = 0\n",
    "while i < 3:\n",
    "    if i==2:\n",
    "        axs[i].plot(total_plot[total_plot.columns.values[i]], '.', markersize=1, color='darkblue')\n",
    "        axs[i].plot(total_plot[total_plot.columns.values[i+3]], '.', markersize=1, color='red')\n",
    "        axs[i].plot(total_plot[total_plot.columns.values[i+6]], '.', markersize=1, color='darkgreen')\n",
    "        #axs[i].plot(total_plot[total_plot.columns.values[i+9]], '.', markersize=1, color='orange')\n",
    "        #axs[i].plot(total_plot[total_plot.columns.values[i+12]], '.', markersize=1, color='purple')\n",
    "        axs[i].set_ylabel(labels[i], fontsize=14, fontweight='bold')\n",
    "        axs[i].grid()\n",
    "        axs[i].set_xlim(ini, end)\n",
    "        axs[i].set_xticks(np.arange(pd.to_datetime(ini), pd.to_datetime(end), td(days=30.5)))\n",
    "        axs[i].tick_params(direction='in')\n",
    "        axs[i].set_xticklabels(months, fontsize=14, fontweight='bold')\n",
    "    else:\n",
    "        axs[i].plot(total_plot[total_plot.columns.values[i]], color='darkblue', linewidth=1)\n",
    "        axs[i].plot(total_plot[total_plot.columns.values[i+3]], color='red', linewidth=1)\n",
    "        axs[i].plot(total_plot[total_plot.columns.values[i+6]], color='darkgreen', linewidth=1)\n",
    "        #axs[i].plot(total_plot[total_plot.columns.values[i+9]], color='orange', linewidth=1)\n",
    "        #axs[i].plot(total_plot[total_plot.columns.values[i+12]], color='purple', linewidth=1)\n",
    "        axs[i].set_ylabel(labels[i], fontsize=14, fontweight='bold')\n",
    "        axs[i].grid()\n",
    "        axs[i].tick_params(direction='in')\n",
    "    fig.legend(['Buoy', 'CSIRO Agg', 'CSIRO Spec'], loc=(0.65, 0.04), ncol=3, fontsize=14)\n",
    "    i += 1\n",
    "    \n",
    "# rbff.buoy_validation(validation_data, 'BUOY NAME', 'agg')\n",
    "# rbff.buoy_validation(validation_data, 'BUOY NAME', 'spec')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
